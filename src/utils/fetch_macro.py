import yfinance as yf
import pandas as pd
from fredapi import Fred
from datetime import datetime
from config.schema_macro import UNIFIED_MACRO_COLUMNS
# ë³‘ë ¬ I/O ì²˜ë¦¬ for loopë³´ë‹¤ 10ë°°ëŠ” ë” ë¹ ë¦„
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# âœ… 1ï¸âƒ£ MultiIndex ì»¬ëŸ¼ ìë™ flatten í•¨ìˆ˜
def flatten_columns(df: pd.DataFrame) -> pd.DataFrame:
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = ['_'.join([str(c) for c in col if c]).strip() for col in df.columns]
    return df
import pandas as pd

# âœ… ì‹œê³„ì—´ìš© FREquency ìƒì„± í•¨ìˆ˜ FREDë‚˜ yfinanceì—ëŠ” ì—†ìŒ.
def detect_frequency(df: pd.DataFrame, date_col: str = "date") -> str:
    """
    ì£¼ì–´ì§„ ì‹œê³„ì—´ DataFrameì—ì„œ date ê°„ê²©ì„ ë¶„ì„í•˜ì—¬
    freq(D/M/Q/A) ê°’ì„ ìë™ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.
    """
    if date_col not in df.columns or len(df) < 2:
        return None

    # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
    diffs = df[date_col].sort_values().diff().dropna().dt.days
    median_diff = diffs.median()

    # ëŒ€í‘œì ì¸ ì¼ìˆ˜ ê¸°ì¤€
    if median_diff <= 2:
        return "D"  # Daily
    elif median_diff <= 31:
        return "M"  # Monthly
    elif median_diff <= 95:
        return "Q"  # Quarterly
    elif median_diff <= 370:
        return "A"  # Annual
    else:
        return None


def apply_unified_schema(df: pd.DataFrame, source: str, defaults: dict = None):
    """
    ëª¨ë“  macro ë°ì´í„°í”„ë ˆì„ì— í†µì¼ëœ ì»¬ëŸ¼ ìŠ¤í‚¤ë§ˆë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    ëˆ„ë½ëœ ì»¬ëŸ¼ì€ None ë˜ëŠ” defaultsë¡œ ì±„ì›ë‹ˆë‹¤.
    """
    if defaults is None:
        defaults = {}

    # ê¸°ë³¸ í•„ë“œ
    df["source"] = source
    df["retrieved_at"] = datetime.now().strftime("%Y-%m-%d")

    # ëª¨ë“  ëˆ„ë½ëœ ì»¬ëŸ¼ ì±„ìš°ê¸°
    for col in UNIFIED_MACRO_COLUMNS:
        if col not in df.columns:
            df[col] = defaults.get(col, None)

    # ìˆœì„œ í†µì¼
    df = df[UNIFIED_MACRO_COLUMNS]

    return df


# âœ… 2ï¸âƒ£ ì§€í‘œ ë°ì´í„° ìˆ˜ì§‘ (í™•ì¥ì„± ë†’ì€ ë²„ì „)
# src/utils/fetch_macro.py


def fetch_macro_indices(indices_dict, start_date, end_date, fred_api_key=None, logger=None, max_workers=8):
    """
    âœ… ë³‘ë ¬ FRED + yfinance ê±°ì‹œì§€í‘œ ìˆ˜ì§‘ í•¨ìˆ˜ (long-form)
    Returns: long-form DataFrame [date, index_name, value_norm, ...]
    """

    fred = Fred(api_key=fred_api_key) if fred_api_key else None
    indices = indices_dict.get("macro_indices_dict", indices_dict)

    success, failed = [], []

    # -------------------------------
    # ë‚´ë¶€ fetch í•¨ìˆ˜ (ê° ì¸ë±ìŠ¤ ê°œë³„ ì²˜ë¦¬)
    # -------------------------------
    def fetch_one(name, code):
        df = None
        try:
            # 1ï¸âƒ£ FRED ì‹œë„
            if fred and code.isupper():
                fred_series = fred.get_series(code, observation_start=start_date, observation_end=end_date)
                if fred_series is not None and not fred_series.empty:
                    df = fred_series.reset_index()
                    df.columns = ["date", "value_norm"]
                    df = apply_unified_schema(df, source="FRED")
                    df["ticker"] = code
                    df["freq"] = detect_frequency(df, "date")
                    df["index_name"] = name
                    if logger:
                        logger.info(f"ğŸ“ˆ FRED: {name} ({code}) â€” {len(df)} points")
            # 2ï¸âƒ£ yfinance ì‹œë„
            if df is None:
                data = yf.download(code, start=start_date, end=end_date, progress=False, auto_adjust=True)
                if data.empty:
                    if logger:
                        logger.warning(f"âš ï¸ No yfinance data for {name} ({code})")
                    return None
                data = data[["Close"]].reset_index()
                data.columns = ["date", "value_norm"]
                data = apply_unified_schema(data, source="yfinance")
                data["ticker"] = code
                data["freq"] = detect_frequency(data, "date")
                data["index_name"] = name
                if logger:
                    logger.info(f"âœ… yfinance: {name} ({code}) â€” {len(data)} points")
                df = data

            return df

        except Exception as e:
            if logger:
                logger.error(f"âŒ Failed to fetch {name} ({code}): {e}")
            return None

    # -------------------------------
    # ë³‘ë ¬ ì‹¤í–‰
    # -------------------------------
    all_data = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(fetch_one, name, code): name for name, code in indices.items()}
        for future in as_completed(futures):
            name = futures[future]
            try:
                result = future.result()
                if result is not None:
                    all_data.append(result)
                    success.append(name)
                else:
                    failed.append(name)
            except Exception as e:
                failed.append(name)
                if logger:
                    logger.error(f"âŒ Thread failed for {name}: {e}")

    # -------------------------------
    # ë°ì´í„° ë³‘í•© + ì •ë ¬
    # -------------------------------
    if not all_data:
        if logger:
            logger.error("âŒ No macro data fetched at all.")
        return pd.DataFrame(columns=UNIFIED_MACRO_COLUMNS)

    df_all = pd.concat(all_data, ignore_index=True)
    df_all = df_all.sort_values(["index_name", "date"]).drop_duplicates()

    # -------------------------------
    # long-form ë³€í™˜
    # -------------------------------
    long_df = (
        df_all
        .reindex(columns = UNIFIED_MACRO_COLUMNS)
        .reset_index(drop=True)
    )

    # -------------------------------
    # ë©”íƒ€ í†µê³„ ì¶œë ¥
    # -------------------------------
    if logger:
        logger.info(f"ğŸ“Š Macro indices fetched: {len(success)} succeeded, {len(failed)} failed.")
        if failed:
            logger.warn(f"âš ï¸ Failed indices: {failed}")
        logger.info(f"âœ… Final long_df shape: {long_df.shape}")

    return long_df



# def fetch_macro_indices(indices_dict, start_date, end_date, fred_api_key=None, logger=None):
#     """
#     Fetch macroeconomic and financial indices from Yahoo Finance and FRED.
#     Compatible with both yfinance tickers (e.g. ^GSPC) and FRED codes (e.g. DGS10, M2SL).

#     Args:
#         indices_dict (dict): { "S&P500": "^GSPC", "DGS10": "DGS10", ... }
#         start_date (date or str)
#         end_date (date or str)
#         fred_api_key (str, optional)
#         logger (logging.Logger, optional): custom logger for structured output

#     Returns:
#         pd.DataFrame with columns: [date, index_name, value_norm]
#     """

#     fred = Fred(api_key=fred_api_key) if fred_api_key else None
#     indices = indices_dict.get("macro_indices_dict", indices_dict)


#     all_data = []
#     success, failed = [], []

#     for name, code in indices.items():
#         try:
#             df = None

#             # -------------------------------
#             # 1ï¸âƒ£ FREDë¡œ ì‹œë„ (ê¸ˆë¦¬, M2, CPI ë“±)
#             # -------------------------------
#             if fred and code.isupper():
#                 try:
#                     fred_series = fred.get_series(code, observation_start=start_date, observation_end=end_date)
#                     if fred_series is not None and not fred_series.empty:
#                         df = fred_series.reset_index()
#                         df.columns = ["date", "value_norm"]
                        
#                         # refactor the columns into UNIFIED_COLUMNS
#                         df = apply_unified_schema(df, source="FRED")
#                         df["ticker"] = code
#                         df["freq"] = detect_frequency(df = df, date_col = "date") 
# # df_fred = df_fred.reindex(columns=UNIFIED_COLUMNS)
# # df_yf = df_yf.reindex(columns=UNIFIED_COLUMNS)
# # df_all = pd.concat([df_yf, df_fred], ignore_index=True)
#                         df["index_name"] = name
#                         success.append(name)
#                         if logger:
#                             logger.info(f"ğŸ“ˆ FRED: {name} ({code}) â€” {len(df)} points")
#                     else:
#                         if logger:
#                             logger.warn(f"âš ï¸ No FRED data for {name} ({code})")

#                 except Exception as e:
#                     if logger:
#                         logger.warn(f"âš ï¸ FRED fetch failed for {name} ({code}): {e}")

#             # -------------------------------
#             # 2ï¸âƒ£ yfinanceë¡œ ì‹œë„ (ì£¼ê°€, í™˜ìœ¨ ë“±)
#             # -------------------------------
#             if df is None:
#                 data = yf.download(code, start=start_date, end=end_date, progress=False, auto_adjust=True)
#                 if data.empty:
#                     failed.append(name)
#                     if logger:
#                         logger.warn(f"âš ï¸ No yfinance data for {name} ({code})")
#                     continue
                
#                 data = data[["Close"]].reset_index()
#                 data.columns = ["date", "value_norm"] # change column names to these
#                 data = apply_unified_schema(df= data, source="yfinance")
#                 data["ticker"] = code
#                 data["freq"] = detect_frequency(df = data, date_col = "date") 
#                 data["index_name"] = name # we are iterating name now
#                 df = data
#                 success.append(name) # success log
#                 if logger:
#                     logger.info(f"âœ… yfinance: {name} ({code}) â€” {len(df)} points")

#             all_data.append(df)

#         except Exception as e:
#             failed.append(name)
#             if logger:
#                 logger.error(f"âŒ Failed to fetch {name} ({code}): {e}")

#     # -------------------------------
#     # 3ï¸âƒ£ ë³‘í•© ë° ì „ì²˜ë¦¬
#     # -------------------------------
#     if not all_data:
#         if logger:
#             logger.error("âŒ No macro data fetched at all.")
#         return pd.DataFrame(columns=UNIFIED_MACRO_COLUMNS)

#     df_all = pd.concat(all_data, ignore_index=True)
#     df_all = df_all.sort_values(["index_name", "date"]).drop_duplicates()

#     # Long-formìœ¼ë¡œ ë³€í™˜
#     long_df = df_all.reset_index().melt(id_vars="date", var_name="index_name", value_name="value_norm")

#     # -------------------------------
#     # 5ï¸âƒ£ ë©”íƒ€ í†µê³„ ì¶œë ¥
#     # -------------------------------
#     if logger:
#         logger.info(f"ğŸ“Š Macro indices fetched: {len(success)} succeeded, {len(failed)} failed.")
#         if failed:
#             logger.warn(f"âš ï¸ Failed indices: {failed}")
#         logger.info(f"âœ… Final long_df shape: {long_df.shape}")

#     return long_df


# def fetch_macro_indices_FRED(indices, start_date, end_date, FRED_API_KEY):
#     '''
#     Fetch multiple macroeconomic indicators from FRED.
    
#     datatype: JSON-like
#     example record:
#     {
#         "realtime_start": "2025-10-29",
#         "realtime_end": "2025-10-29",
#         "date": "1974-01-01",
#         "value": "6145.506"
#     }

#     Parameters:
#         indices (list): list of FRED Series IDs (e.g., ['CPIAUCSL', 'FEDFUNDS', 'SP500'])
#         start_date (str): start date in 'YYYY-MM-DD' format
#         end_date (str): end date in 'YYYY-MM-DD' format
#         FRED_API_KEY (str): your FRED API key
#     Returns:
#         pd.DataFrame: concatenated dataframe with columns ['date', 'value', 'index_name']
#     '''

#     fred = Fred(api_key=FRED_API_KEY)
#     df_list = []

#     for idx in indices:
#         try:
#             # fetch data from FRED
#             data = fred.get_series(idx, observation_start=start_date, observation_end=end_date)
#             df = data.reset_index()
#             df.columns = ["date", "value"]
#             df["index_name"] = idx
#             df_list.append(df)
#         except Exception as e:
#             print(f"âš ï¸ Failed to fetch {idx}: {e}")
#             continue

#     if not df_list:
#         return pd.DataFrame(columns=["date", "value", "index_name"])

#     return pd.concat(df_list, ignore_index=True)